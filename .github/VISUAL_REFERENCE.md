# Visual Reference: RoleForge vs SillyTavern LLM Client

## Architecture Comparison Diagram

### SillyTavern Model (clientOverhaulStories.md)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Browser/Frontend                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  User Interface                               â”‚  â”‚
â”‚  â”‚  - Backend selector dropdown                  â”‚  â”‚
â”‚  â”‚  - Model picker                               â”‚  â”‚
â”‚  â”‚  - Template preset selector                   â”‚  â”‚
â”‚  â”‚  - Parameter sliders                          â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Node.js Proxy Server (server.js)       â”‚
â”‚  Handles CORS, proxies requests                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼           â–¼           â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI   â”‚ â”‚KoboldAI â”‚ â”‚Claude  â”‚ â”‚OpenRouterâ”‚
â”‚Extension â”‚ â”‚Extensionâ”‚ â”‚Ext.    â”‚ â”‚Extension â”‚
â”‚          â”‚ â”‚         â”‚ â”‚        â”‚ â”‚          â”‚
â”‚getSettings
â”‚generate()â”‚ â”‚generate()
â”‚getModels â”‚ â”‚getModels()
â”‚          â”‚ â”‚getModels()
â”‚          â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### RoleForge Current Model
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              React Frontend                         â”‚
â”‚  - Chat interface                                   â”‚
â”‚  - Character/World managers                         â”‚
â”‚  âœ— NO LLM config UI                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
       Socket.io (Real-time)
                  â”‚
                  â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          Node.js Express Server                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Orchestrator.ts                     â”‚   â”‚
â”‚  â”‚  - Coordinates agents                        â”‚   â”‚
â”‚  â”‚  - Manages context/history                   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Character   â”‚ Narrator â”‚ Director â”‚ World   â”‚   â”‚
â”‚  â”‚ Agent       â”‚ Agent    â”‚ Agent    â”‚ Agent   â”‚   â”‚
â”‚  â”‚ (BaseAgent extends)                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚           â–¼                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  LLM Client (client.ts)                     â”‚   â”‚
â”‚  â”‚  - OpenAI SDK wrapper                       â”‚   â”‚
â”‚  â”‚  - âœ— NO other backends                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ OpenAI API   â”‚  â”‚KoboldCPP     â”‚
    â”‚ (native)     â”‚  â”‚(OpenAI compat)
    â”‚              â”‚  â”‚              â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Feature Comparison Matrix

```
FEATURE                          SILLY TAVERN      ROLEFORGE         STATUS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Backend Types                    20+               1 (OpenAI-compat) âœ—
â””â”€ OpenAI                        âœ“                 âœ“                 âœ“
â””â”€ Claude/Anthropic              âœ“                 âœ—                 âœ—
â””â”€ KoboldAI/CPP                  âœ“                 âœ“ (via endpoint)  âœ“
â””â”€ OpenRouter                    âœ“                 âœ— (workaround)    âœ—

Template Types                   Multiple JSON     Multiple .njk     âš ï¸
â””â”€ ChatML                        âœ“                 âœ“                 âœ“
â””â”€ Alpaca                        âœ“                 âœ— (code ready)    âš ï¸
â””â”€ Vicuna                        âœ“                 âœ— (code ready)    âš ï¸
â””â”€ Llama2                        âœ“                 âœ— (code ready)    âš ï¸

Runtime Switching                UI Dropdown       Config reload     âœ—
Model Discovery                  API (/v1/models)  âœ—                 âœ—
Frontend Config UI               Full              âœ—                 âœ—

Task Agents                      Extensions        Classes           âœ“
Prompt Templating                Manual builder    Nunjucks (better) âœ“
Context Trimming                 Implicit          Smart trimming    âœ“
Streaming                        Browser           Via Socket.io     âœ“
JSON Responses                   Supported         Supported         âœ“
Error Fallback                   Chains            âœ—                 âœ—
Retry Logic                      âœ“                 âœ—                 âœ—
```

---

## Configuration Hierarchy

### SillyTavern (Not explicit in spec, inferred)
```
Extension Defaults
       â–²
       â””â”€â”€â”€ User Settings (UI)
            â””â”€â”€â”€ Per-Generation Overrides
```

### RoleForge
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      Default Sampler Settings           â”‚
â”‚   (built into sampler definitions)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Global Profile (config.json)          â”‚
â”‚   profiles.default.sampler              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Agent Override (config.json)          â”‚
â”‚   agents.character.sampler              â”‚
â”‚   (merges with profile sampler)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â–¼
          Final Settings Used
    (profile + agent override)
```

---

## Template System Comparison

### SillyTavern JSON Preset
```json
{
  "name": "alpaca",
  "system_prefix": "### Instruction:\n",
  "system_suffix": "\n",
  "user_prefix": "### Input:\n",
  "user_suffix": "\n",
  "assistant_prefix": "### Response:\n",
  "assistant_suffix": "\n",
  "stop_sequence": ["### Instruction:", "### Input:"]
}
```
Runtime: User selects â†’ Wraps all messages with prefixes/suffixes

### RoleForge Nunjucks Template
```njk
<|im_start|>system
{{system_prompt}}<|im_end|>
<|im_start|>user
{{user_message}}<|im_end|>
<|im_start|>assistant
{{assistant_message}}<|im_end|>
```
Runtime: Profile specifies template name â†’ Loads `.njk` file â†’ Renders

**Difference**: 
- SillyTavern: Data-driven (JSON structure wrapped procedurally)
- RoleForge: Template-driven (Nunjucks renders directly)

Both approaches are valid; RoleForge is more declarative.

---

## Context Building Process

### SillyTavern (Inferred from spec)
```
User Input
    â–¼
PromptManager.buildPrompt()
    â”‚
    â”œâ”€ Add system prompt
    â”œâ”€ Add World Info (triggered by keywords)
    â”œâ”€ Add character card
    â”œâ”€ Add chat history (wrapped per template)
    â”œâ”€ Add user input
    â”œâ”€ Add author's note (if configured)
    â””â”€ Add jailbreak (if configured)
    â–¼
Trim by token budget (if max context set)
    â–¼
Apply template wrapping (template.system_prefix, etc.)
    â–¼
Send to backend
```

### RoleForge
```
User Input
    â–¼
Orchestrator.processUserInput()
    â”‚
    â”œâ”€ Format history into history[]
    â”œâ”€ Call LorebookService.getLoreContext()
    â”œâ”€ Match lore entries (keyword matching)
    â”œâ”€ Build AgentContext object
    â”‚   {history, formattedLore, character, worldState, ...}
    â”‚
    â””â”€ Call DirectorAgent
         â”‚
         â”œâ”€ Call renderTemplate('director', context)
         â”‚   â””â”€ Renders director.njk with context
         â”‚
         â”œâ”€ Call renderLLMTemplate(systemPrompt, userMessage)
         â”‚   â””â”€ Loads llm_templates/{profile.template}.njk
         â”‚   â””â”€ Renders with {{system_prompt}}, {{user_message}}
         â”‚
         â””â”€ Call chatCompletion(profile, messages)
              â”‚
              â”œâ”€ Trim messages to maxContextTokens
              â””â”€ Send to LLM API
```

---

## Error Handling Flow

### SillyTavern (Implied)
```
Try Primary Model
    â–¼
  Fail?
    â”œâ”€ YES: Log error
    â”‚       Try Fallback Model 1
    â”‚           â–¼
    â”‚         Fail?
    â”‚           â”œâ”€ YES: Try Fallback Model 2
    â”‚           â”‚       ...
    â”‚           â””â”€ NO: Success âœ“
    â”‚
    â””â”€ NO: Success âœ“
```

### RoleForge Current
```
Try LLM API
    â–¼
  Error?
    â”œâ”€ YES: Log error
    â”‚       throw error âœ—
    â”‚       (Orchestrator catches, emits error event)
    â”‚
    â””â”€ NO: Success âœ“
```

**Issue**: No recovery mechanism

---

## Template File Organization

### SillyTavern
```
data/
â”œâ”€ instruct-presets/
â”‚  â”œâ”€ alpaca.json
â”‚  â”œâ”€ vicuna.json
â”‚  â”œâ”€ llama2.json
â”‚  â”œâ”€ chatml.json
â”‚  â””â”€ ...
```
**Selection**: User picks from dropdown â†’ loads JSON â†’ applies at runtime

### RoleForge Current
```
backend/src/
â”œâ”€ llm_templates/
â”‚  â””â”€ chatml.njk          (ONLY ONE!)
â””â”€ prompts/
   â”œâ”€ character.njk       (task-specific)
   â”œâ”€ narrator.njk        (task-specific)
   â”œâ”€ director.njk        (task-specific)
   â””â”€ ...
```
**Selection**: Profile specifies `template: "chatml"` â†’ loads chatml.njk â†’ renders

**Missing**:
```
backend/src/llm_templates/
â”œâ”€ chatml.njk
â”œâ”€ alpaca.njk           â† NEEDED
â”œâ”€ vicuna.njk           â† NEEDED
â”œâ”€ llama2.njk           â† NEEDED
â””â”€ ...
```

---

## Backend Selector Flow

### SillyTavern
```
User clicks backend dropdown
    â–¼
Select "Claude"
    â–¼
Load extensions/claude/index.js dynamically
    â–¼
Call getSettings() â†’ get default params
    â–¼
Call getModelList() â†’ query Anthropic API
    â–¼
Display available models
    â–¼
User selects model
    â–¼
generate(prompt, model) is called
```

### RoleForge Current
```
Edit config.json
    â–¼
Set defaultProfile: "openai"
    â–¼
Set profiles.openai.baseURL: "..."
    â–¼
Server reads config.json on startup
    â–¼
Hardcoded OpenAI SDK used
    â–¼
Only OpenAI-compatible backends work
```

**No Dynamic Discovery**: Would need `/api/models` endpoint

---

## Critical Issues Visualization

### Issue 1: Missing Template Files
```
config.json says:
  "template": "alpaca"
       â–¼
BaseAgent.renderLLMTemplate() tries:
  llm_templates/alpaca.njk
       â–¼
File NOT FOUND âœ—
       â–¼
Runtime Error
```

**Fix**: Create alpaca.njk, vicuna.njk, etc.

### Issue 2: No Error Recovery
```
LLM API Call Fails
       â–¼
console.error('...')
       â–¼
throw error âœ—
       â–¼
User sees error, no retry
       â–¼
Session breaks
```

**Fix**: Implement fallback profiles, retry logic

### Issue 3: No Backend Support
```
Want to use Claude:
       â–¼
Configure baseURL to Claude API
       â–¼
OpenAI SDK can't handle Claude API format
       â–¼
LLM call fails âœ—
```

**Fix**: Implement backend adapter pattern (significant effort)

---

## Feature Implementation Roadmap

```
Current (NOW)
â”œâ”€ âœ“ OpenAI-compatible
â”œâ”€ âœ“ ChatML template
â”œâ”€ âœ“ Streaming
â”œâ”€ âœ“ Token trimming
â””â”€ âœ“ Agent system

Phase 1 (2-3 hours) ğŸš€
â”œâ”€ âœ“ Create template files
â”œâ”€ âœ“ Fix template loading
â”œâ”€ âœ“ Document templates
â””â”€ âœ“ Add error handling

Phase 2 (3-4 hours)
â”œâ”€ â–¡ Retry logic
â”œâ”€ â–¡ Fallback chains
â””â”€ â–¡ Error tests

Phase 3 (1-2 weeks)
â”œâ”€ â–¡ Frontend config UI
â”œâ”€ â–¡ Model discovery
â””â”€ â–¡ Parameter UI

Phase 4 (2-3 days, optional)
â”œâ”€ â–¡ Backend adapters
â”œâ”€ â–¡ Claude support
â””â”€ â–¡ OpenRouter support
```

---

## Decision Tree

```
Do we need Claude/Anthropic support?
    â”‚
    â”œâ”€ NO
    â”‚   â””â”€ Document OpenAI-only limitation
    â”‚       â””â”€ Fix templates (2-3 hours)
    â”‚           â””â”€ DONE
    â”‚
    â””â”€ YES
        â”œâ”€ Now? â†’ Implement adapters (2-3 days)
        â”‚
        â””â”€ Later? â†’ Add to roadmap, fix templates first
```

```
Should templates be UI-switchable?
    â”‚
    â”œâ”€ NO (current)
    â”‚   â””â”€ Keep config-file approach
    â”‚       â””â”€ Document it
    â”‚
    â””â”€ YES
        â”œâ”€ Via config reload? (1 hour)
        â”‚
        â””â”€ Via UI? (4-6 hours)
            â””â”€ Create LLMConfigModal component
```

---

## Code Diff: Where Changes Needed

```
CRITICAL CHANGES:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

File: backend/src/agents/BaseAgent.ts
Line: 185

Current:
  const templateName = profile.template || 'chatml';
  const templatePath = path.join(..., `${templateName}.njk`);
  
Issue: Only chatml.njk exists; others fail silently or crash

Fix: Add file existence check + fallback

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Files Needed: backend/src/llm_templates/
  âœ“ chatml.njk        (EXISTS)
  âœ— alpaca.njk        (NEEDED)
  âœ— vicuna.njk        (NEEDED)
  âœ— llama2.njk        (OPTIONAL)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

File: backend/src/llm/client.ts
Line: ~125 (catch block)

Current:
  catch (error) {
    console.error(...);
    throw error;  // No recovery
  }

Fix: Implement fallback profile retry

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Optional: backend/src/llm/client.ts
Add backend adapter pattern:
  - Create backends/openai.ts
  - Create backends/anthropic.ts
  - Route through adapters in client.ts
```

---

## Success Criteria Checklist

After implementing fixes:

- [ ] Templates can be switched via profile.template
- [ ] Other templates (Alpaca, Vicuna) work correctly
- [ ] Error with primary backend triggers fallback
- [ ] Retry logic implements exponential backoff
- [ ] All tests pass
- [ ] Documentation complete
- [ ] No breaking changes

---

End of Visual Reference  
See README_LLM_ANALYSIS.md for document navigation
